{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis y Reporte sobre el desempeño del modelo\n",
    "\n",
    "Daniel Salvador Cázares García A01197517\n",
    "\n",
    "En este breve reporte se hará un análisis acerca del desempeño de un modelo de machine learning implementado con la librería sklearn, que utiliza la técnica de Random Forest Regressor para realizar predicciones de precios de bienes raíces para el dataset \"Real estate price prediction\". Así mismo, se utilizarán técnicas de regularización y ajuste para intentar mejorar el desempeño.\n",
    "\n",
    "**Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 414 entries, 1 to 414\n",
      "Data columns (total 7 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   X1 transaction date                     414 non-null    float64\n",
      " 1   X2 house age                            414 non-null    float64\n",
      " 2   X3 distance to the nearest MRT station  414 non-null    float64\n",
      " 3   X4 number of convenience stores         414 non-null    int64  \n",
      " 4   X5 latitude                             414 non-null    float64\n",
      " 5   X6 longitude                            414 non-null    float64\n",
      " 6   Y house price of unit area              414 non-null    float64\n",
      "dtypes: float64(6), int64(1)\n",
      "memory usage: 25.9 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Real estate.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos en columnas para entrenamiento (X) y para predicción (y)\n",
    "X = df[['X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']]\n",
    "y = df['Y house price of unit area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del desempeño\n",
    "\n",
    "En esta primera parte, se busca analizar el desempeño de la implementación ya realizada. La técnica de Machine Learning seleccionada fue **Random Forest Regressor** con sklearn. El objetivo es predecir el valor de la variable `Y house price of unit area` con base en las variables `X`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de datos en conjuntos entrenamiento, validación y prueba\n",
    "\n",
    "El primer paso antes de entrenar el modelo es separar los datos en 3 conjuntos: entrenamiento, validación y prueba. En este caso, los datos se dividieron de la siguiente forma:\n",
    "* Entrenamiento: 80%\n",
    "* Validación: 10%\n",
    "* Prueba: 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rest, y_train, y_rest = train_test_split(X,y, train_size=0.8, random_state=42)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de datos:  414\n",
      "Entrenamiento:  331\n",
      "Validación:  41\n",
      "Prueba:  42\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de datos: \", len(df))\n",
    "print(\"Entrenamiento: \", len(X_train))\n",
    "print(\"Validación: \", len(X_val))\n",
    "print(\"Prueba: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "\n",
    "Se entreno el modelo con la técnica de Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, random_state=42, criterion=\"squared_error\")\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis del desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7515455801398772"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que el modelo tiene un score de 0.75 con los datos de validación, lo cual indica que el este tiene un desempeño aceptable. Sin embargo, existe la posibilidad de que este valor sea mejorable al ajustar parametros y transformar los datos.\n",
    "\n",
    "**Error (MSE y RMSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, bias, var = bias_variance_decomp(regressor, X_train.values, y_train.values, X_val.values, y_val.values, loss='mse', num_rounds=200, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  57.10302988405323\n",
      "RMSE:  7.556654675453499\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grado de bias (sesgo) y varianza**\n",
    "\n",
    "Por lo general, las técnicas de Random Forest deben tener un sesgo bajo y una alta varianza, lo que se traduce en un Overfitting. A continuación se observan las métricas obtenidas para el modelo realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  41.85468279469873\n",
      "Varianza:  15.248347089354535\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias: \", bias)\n",
    "print(\"Varianza: \", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nivel de ajuste**\n",
    "\n",
    "Se puede observar que el bias es considerablemente mayor que la varianza, por lo que puede existir cierto grado de **Underfitting**. Además, ambos valores son elevados, lo que puede provocar que el modelo sea inconsistente y no tenga una buena precisión. Sin embargo, hay que considerar que todavía no se ha hecho escalamiento de los datos, lo cual puede impactar fuertemente a modelos como Random Forest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora del modelo\n",
    "\n",
    "Como se pudo observar, el primer modelo no obtuvo tan buenos resultados. Por lo tanto, se buscará mejorarlo. Para mejorar los resultados del modelo, existen 2 tareas importantes: preprocesamiento de los datos y ajuste de parámetros.\n",
    "\n",
    "### Preprocesamiento de datos\n",
    "\n",
    "**Escalamiento**\n",
    "\n",
    "Un procedimiento que no se realizo al inicio y que si tiene impacto en algoritmos como regresión lineal o Random Forest es el escalamiento de los datos. A continuación se hará un escalamiento de las variables de entrenamiento con el módulo StandardScaler de sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) # Entrenamiento\n",
    "X_val = sc.transform(X_val) # Validación\n",
    "X_test = sc.transform(X_test) # Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducción de variables**\n",
    "\n",
    "Antes de pasar al ajuste de parámetros, también se puede observar la importancia que tienen las diferentes columnas en los resultados del modelo. Para de esta forma, remover aquellas que no sean significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X3 distance to the nearest MRT station    0.587487\n",
       "X2 house age                              0.191782\n",
       "X5 latitude                               0.129762\n",
       "X6 longitude                              0.062155\n",
       "X4 number of convenience stores           0.028814\n",
       "dtype: float64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp = pd.Series(regressor.feature_importances_,index=['X2 house age', 'X3 distance to the nearest MRT station', 'X4 number of convenience stores', 'X5 latitude', 'X6 longitude']).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, la variable X4 number of convenience stores tiene poca importancia, por lo que se decidio probar eliminarla para observar cómo se ve afectado el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de columnas\n",
    "X = df[['X2 house age', 'X3 distance to the nearest MRT station', 'X5 latitude', 'X6 longitude']]\n",
    "y = df['Y house price of unit area']\n",
    "\n",
    "# División en conjuntos de datos\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X,y, train_size=0.8, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)\n",
    "\n",
    "# Escalamiento\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) # Entrenamiento\n",
    "X_val = sc.transform(X_val) # Validación\n",
    "X_test = sc.transform(X_test) # Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste de hiperpárametros\n",
    "\n",
    "Ya realizado un preprocesamiento de los datos, ahora se busca encontrar los párametros que permitan mejorar los resultados. Para encontrar los mejores hiperpárametros se uso GridSearchCV, el cual permite entrenar al modelo con distintas combinaciones de párametros para encontrar la combinación más óptima.\n",
    "\n",
    "Los párametros a probar son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'max_features': [2, 3],\n",
    "    'max_depth': [10, 50, 100, 200],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=200, max_features=3, n_estimators=300)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=200, max_features=3, n_estimators=300)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=200, max_features=3, n_estimators=300)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = RandomForestRegressor()\n",
    "reg_tuned = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "reg_tuned.fit(X_train, y_train)\n",
    "reg_tuned.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los parametros que mejores resultados obtuvieron fueron los anteriores. Ahora ya solo queda volver a entrenar el modelo con los parámetros recomendados y el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "newReg = RandomForestRegressor(n_estimators=300, max_features=3, max_depth=200, random_state=42, criterion=\"squared_error\")\n",
    "newReg.fit(X_train, y_train)\n",
    "predictions = newReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desempeño del nuevo modelo\n",
    "\n",
    "Ya por último, solo toca comparar las métricas para observar si se logro mejorar el modelo.\n",
    "\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.79176455301811"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = abs(predictions - y_test)\n",
    "accuracy = 100 - (100 * np.mean(error / y_test))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy aumento a 88.79, con lo cual se puede observar que el desempeño aumento de forma considerable.\n",
    "\n",
    "**MSE y RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, bias, var = bias_variance_decomp(newReg, X_train, y_train.values, X_test, y_test.values, loss='mse', num_rounds=200, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  28.74700373745699\n",
      "RMSE:  5.3616232371789225\n"
     ]
    }
   ],
   "source": [
    "print(\"MSE: \", mse)\n",
    "print(\"RMSE: \", mse**(1/2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que el error también disminuyo notoriamente.\n",
    "\n",
    "**Bias y varianza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias:  20.873299671965142\n",
      "Varianza:  7.87370406549183\n"
     ]
    }
   ],
   "source": [
    "print(\"Bias: \", bias)\n",
    "print(\"Varianza: \", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya por último, se puede ver que del mismo modo, que el accuracy y el error, el bias y la varianza también mejoraron. Sin embargo, sigue existiendo cierto grado de Underfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80c6652192cedd01087cfbb01dd5c317f6e95c921b1a034918363f84abb58a87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
